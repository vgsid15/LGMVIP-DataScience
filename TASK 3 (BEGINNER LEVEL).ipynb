{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siddhaarthan V\n",
    "# MUSIC RECOMMENDATION SYSTEM\n",
    "# TASK 3 BEGINNER LEVEL TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.3.2-py3-none-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\siddhaarthan\\anaconda3\\lib\\site-packages (from lightgbm) (1.0.2)\n",
      "Requirement already satisfied: wheel in c:\\users\\siddhaarthan\\anaconda3\\lib\\site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\siddhaarthan\\anaconda3\\lib\\site-packages (from lightgbm) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\siddhaarthan\\anaconda3\\lib\\site-packages (from lightgbm) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\siddhaarthan\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\siddhaarthan\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = pd.read_csv('members.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_csv('songs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntr = 7000\n",
    "nts = 3000\n",
    "names=['msno','song_id','source_system_tab','source_screen_name','source_type','target']\n",
    "test1 = pd.read_csv('train.csv',names=names,skiprows=ntr,nrows=nts)\n",
    "test = test1.drop(['target'],axis=1)\n",
    "ytr = np.array(test1['target'])\n",
    "test_name = ['id','msno','song_id','source_system_tab','source_screen_name','source_type']\n",
    "test['id']=np.arange(nts)\n",
    "test = test[test_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_cols = ['song_id', 'artist_name', 'genre_ids', 'song_length', 'language']\n",
    "train = train.merge(songs[song_cols], on='song_id', how='left')\n",
    "test = test.merge(songs[song_cols], on='song_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "members['registration_year'] = members['registration_init_time'].apply(lambda x: int(str(x)[0:4]))\n",
    "members['registration_month'] = members['registration_init_time'].apply(lambda x: int(str(x)[4:6]))\n",
    "members['registration_date'] = members['registration_init_time'].apply(lambda x: int(str(x)[6:8]))\n",
    "members['expiration_year'] = members['expiration_date'].apply(lambda x: int(str(x)[0:4]))\n",
    "members['expiration_month'] = members['expiration_date'].apply(lambda x: int(str(x)[4:6]))\n",
    "members['expiration_date'] = members['expiration_date'].apply(lambda x: int(str(x)[6:8]))\n",
    "members = members.drop(['registration_init_time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "members_cols = members.columns\n",
    "train = train.merge(members[members_cols], on='msno', how='left')\n",
    "test = test.merge(members[members_cols], on='msno', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del members, songs; gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(train.columns)\n",
    "cols.remove('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:28<00:00,  1.52s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for col in tqdm(cols):\n",
    "    if train[col].dtype == 'object':\n",
    "        train[col] = train[col].apply(str)\n",
    "        test[col] = test[col].apply(str)\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        train_vals = list(train[col].unique())\n",
    "        test_vals = list(test[col].unique())\n",
    "        le.fit(train_vals + test_vals)\n",
    "        train[col] = le.transform(train[col])\n",
    "        test[col] = le.transform(test[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_songs = range(max(train['song_id'].max(), test['song_id'].max()))\n",
    "song_popularity = pd.DataFrame({'song_id': unique_songs, 'popularity':0})\n",
    "train_sorted = train.sort_values('song_id')\n",
    "train_sorted.reset_index(drop=True, inplace=True)\n",
    "test_sorted = test.sort_values('song_id')\n",
    "test_sorted.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building of a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train.drop(['target'], axis=1))\n",
    "y = train['target'].values\n",
    "X_test = np.array(test.drop(['id'], axis=1))\n",
    "ids = test['id'].values\n",
    "del train, test; gc.collect();\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state = 12)\n",
    "del X, y; gc.collect();\n",
    "d_train = lgb.Dataset(X_train, label=y_train)\n",
    "d_valid = lgb.Dataset(X_valid, label=y_valid) \n",
    "watchlist = [d_train, d_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(m1_model):\n",
    "    model = m1_model.fit(X_train,y_train)\n",
    "    print('Training Score : {}'.format(model.score(X_train,y_train)))\n",
    "    y_pred = model.predict(X_valid)\n",
    "    v_test = model.predict(X_test)\n",
    "    yhat = (v_test>0.5).astype(int)\n",
    "    comp = (yhat==ytr).astype(int)\n",
    "    acc = comp.sum()/comp.size*100\n",
    "    print(\"Accuracy on test data for the model\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score : 0.5121212239874355\n",
      "Accuracy on test data for the model 63.56666666666667\n"
     ]
    }
   ],
   "source": [
    "predict(LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction using lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.123958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's auc: 0.711178\tvalid_1's auc: 0.710232\n",
      "[20]\ttraining's auc: 0.730905\tvalid_1's auc: 0.728782\n",
      "[30]\ttraining's auc: 0.741549\tvalid_1's auc: 0.738609\n",
      "[40]\ttraining's auc: 0.749137\tvalid_1's auc: 0.745402\n",
      "[50]\ttraining's auc: 0.756133\tvalid_1's auc: 0.751662\n",
      "[60]\ttraining's auc: 0.762364\tvalid_1's auc: 0.757353\n",
      "[70]\ttraining's auc: 0.766309\tvalid_1's auc: 0.760607\n",
      "[80]\ttraining's auc: 0.771415\tvalid_1's auc: 0.76515\n",
      "[90]\ttraining's auc: 0.775364\tvalid_1's auc: 0.768509\n",
      "[100]\ttraining's auc: 0.778289\tvalid_1's auc: 0.770738\n",
      "[110]\ttraining's auc: 0.781535\tvalid_1's auc: 0.773422\n",
      "[120]\ttraining's auc: 0.784836\tvalid_1's auc: 0.776062\n",
      "[130]\ttraining's auc: 0.78777\tvalid_1's auc: 0.778502\n",
      "[140]\ttraining's auc: 0.790916\tvalid_1's auc: 0.780955\n",
      "[150]\ttraining's auc: 0.792893\tvalid_1's auc: 0.782164\n",
      "[160]\ttraining's auc: 0.794461\tvalid_1's auc: 0.782979\n",
      "[170]\ttraining's auc: 0.796242\tvalid_1's auc: 0.784121\n",
      "[180]\ttraining's auc: 0.799067\tvalid_1's auc: 0.786476\n",
      "[190]\ttraining's auc: 0.801161\tvalid_1's auc: 0.788098\n",
      "[200]\ttraining's auc: 0.803267\tvalid_1's auc: 0.789657\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.803267\tvalid_1's auc: 0.789657\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "params['learning_rate'] = 0.4\n",
    "params['application'] = 'binary'\n",
    "params['max_depth'] = 15\n",
    "params['num_leaves'] = 2**8\n",
    "params['verbosity'] = 0\n",
    "params['metric'] = 'auc'\n",
    "model1 = lgb.train(params, train_set=d_train, num_boost_round=200, valid_sets=watchlist, early_stopping_rounds=10, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
